/usr/bin/python3.6 /home/sabrina/PycharmProjects/DMML_CW2/overfitting.py

--------------------------------------------------------
--------------------------------------------------------
--------------CHANGE NUM LAYER & NEURONS----------------
--------------------------------------------------------
--------------------------------------------------------

nn = MLPClassifier(hidden_layer_sizes=1, activation='relu',
                  momentum=0.9, learning_rate_init=0.001, max_iter=200)

Results using train set
0.16729544918651262


Confusion matrix from ten cross validation:
[[  0  81   0   5  63 202   0   0  96   0]
 [  0 152   0   2 127 259   0   0  64   0]
 [  0  13   0   1  63  56   0   0   7   0]
 [  0  47   0   9 172 182   0   0  44   0]
 [  0  43   0   2 346 279   0   0  19   0]
 [  0  11   0   1   7 674   0   0  48   0]
 [  0  18   0   0   6 126   0   0  89   0]
 [  0   9   0   1  31  34   0   0   9   0]
 [  0  13   0   0  10 412   0   0 269   0]
 [  0  11   0   0  25  35   0   0   5   0]]


Classification report
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       447
           1       0.38      0.25      0.30       604
           2       0.00      0.00      0.00       140
           3       0.43      0.02      0.04       454
           4       0.41      0.50      0.45       689
           5       0.30      0.91      0.45       741
           6       0.00      0.00      0.00       239
           7       0.00      0.00      0.00        84
           8       0.41      0.38      0.40       704
           9       0.00      0.00      0.00        76

    accuracy                           0.35      4178
   macro avg       0.19      0.21      0.16      4178
weighted avg       0.29      0.35      0.27      4178

Using test set ------------------------------------------------------------
Results using test set:
0.17266187050359713

Confusion matrix using test set:
[[  0   0   0   0   0 450   0   0   0   0]
 [  0   0   0   0   0 630   0   0   0   0]
 [  0   0   0   0   0 150   0   0   0   0]
 [  0   0   0   0   0 420   0   0   0   0]
 [  0   0   0   0   0 690   0   0   0   0]
 [  0   0   0   0   0 720   0   0   0   0]
 [  0   0   0   0   0 270   0   0   0   0]
 [  0   0   0   0   0  60   0   0   0   0]
 [  0   0   0   0   0 690   0   0   0   0]
 [  0   0   0   0   0  90   0   0   0   0]]

Classification report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       450
           1       0.00      0.00      0.00       630
           2       0.00      0.00      0.00       150
           3       0.00      0.00      0.00       420
           4       0.00      0.00      0.00       690
           5       0.17      1.00      0.29       720
           6       0.00      0.00      0.00       270
           7       0.00      0.00      0.00        60
           8       0.00      0.00      0.00       690
           9       0.00      0.00      0.00        90

    accuracy                           0.17      4170
   macro avg       0.02      0.10      0.03      4170
weighted avg       0.03      0.17      0.05      4170


--------------------------------------------------------

nn1 = MLPClassifier(hidden_layer_sizes=(10, 10), activation='relu',
                    momentum=0.9, learning_rate_init=0.001, max_iter=

Results using train set
0.4646309832586654


Confusion matrix from ten cross validation:
[[  0  79   0   0  35 269   0   0  64   0]
 [  0 137   0   0  64 339   0   0  64   0]
 [  0   1   0   0  58  80   0   0   1   0]
 [  0  41   0   0 174 235   0   0   4   0]
 [  0  14   0   0 270 363   0   0  42   0]
 [  0  11   0   0  17 682   0   0  31   0]
 [  0  17   0   0  27 145   0   0  50   0]
 [  0   5   0   0  26  49   0   0   4   0]
 [  0  17   0   0  63 401   0   0 223   0]
 [  0  12   0   0  14  46   0   0   4   0]]


Classification report
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       447
           1       0.41      0.23      0.29       604
           2       0.00      0.00      0.00       140
           3       0.00      0.00      0.00       454
           4       0.36      0.39      0.38       689
           5       0.26      0.92      0.41       741
           6       0.00      0.00      0.00       239
           7       0.00      0.00      0.00        84
           8       0.46      0.32      0.37       704
           9       0.00      0.00      0.00        76

    accuracy                           0.31      4178
   macro avg       0.15      0.19      0.14      4178
weighted avg       0.24      0.31      0.24      4178

Using test set ------------------------------------------------------------
Results using test set:
0.473621103117506

Confusion matrix using test set:
[[  0   0   0  25 409   9   0   0   7   0]
 [  0   0   0  27 569  16   0   0  18   0]
 [  0   0   0  10   2   0   0   0 138   0]
 [  0   0   0 116 158   2   0   0 144   0]
 [  0   0   0  44 622  13   0   0  11   0]
 [  0   0   0   1  64 653   0   0   2   0]
 [  0   0   0   7   0   0   0   0 263   0]
 [  0   0   0   0   0   0   0   0  60   0]
 [  0   0   0  69  37   0   0   0 584   0]
 [  0   0   0   0  57  32   0   0   1   0]]

Classification report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       450
           1       0.00      0.00      0.00       630
           2       0.00      0.00      0.00       150
           3       0.39      0.28      0.32       420
           4       0.32      0.90      0.48       690
           5       0.90      0.91      0.90       720
           6       0.00      0.00      0.00       270
           7       0.00      0.00      0.00        60
           8       0.48      0.85      0.61       690
           9       0.00      0.00      0.00        90

    accuracy                           0.47      4170
   macro avg       0.21      0.29      0.23      4170
weighted avg       0.33      0.47      0.37      4170


--------------------------------------------------------

nn2 = MLPClassifier(hidden_layer_sizes=(10, 10, 10), activation='relu',
                   momentum =0.9, learning_rate_init=0.001, max_iter=200)

Results using train set
0.9686394718226833


Confusion matrix from ten cross validation:
[[320 104   0   1   4   7   4   0   7   0]
 [ 73 500   1   7  12   3   3   1   4   0]
 [  0   6  88  13  19   1   3  10   0   0]
 [  4   8   0 416  19   2   2   0   3   0]
 [  6  21   5  12 614  12   6   0  13   0]
 [  8   9   0   0  11 696   4   0  11   2]
 [  9   3   3   0   1   5 206   0  11   1]
 [  3   9  10   1  29   0   1  26   5   0]
 [ 13   2   0   4   9   7   8   0 660   1]
 [ 12   7   0   2   2  12   1   0   3  37]]


Classification report
              precision    recall  f1-score   support

           0       0.71      0.72      0.72       447
           1       0.75      0.83      0.79       604
           2       0.82      0.63      0.71       140
           3       0.91      0.92      0.91       454
           4       0.85      0.89      0.87       689
           5       0.93      0.94      0.94       741
           6       0.87      0.86      0.86       239
           7       0.70      0.31      0.43        84
           8       0.92      0.94      0.93       704
           9       0.90      0.49      0.63        76

    accuracy                           0.85      4178
   macro avg       0.84      0.75      0.78      4178
weighted avg       0.85      0.85      0.85      4178

Using test set ------------------------------------------------------------
Results using test set:
0.9182254196642686

Confusion matrix using test set:
[[413  23   6   0   2   4   0   0   2   0]
 [ 54 556   1   3   4   5   0   0   2   5]
 [  8   3 120   0  11   0   0   7   1   0]
 [  0   2   0 381  34   0   0   0   3   0]
 [  3   9   0  10 644   5   1   3  15   0]
 [  5   1   0   1   0 704   0   0   6   3]
 [  1   0   0   0   0   5 246   0  18   0]
 [  0   0   0   0  30   0   0  30   0   0]
 [  1   1   0   4   5  21   1   0 657   0]
 [  0   3   0   1   0   7   0   0   1  78]]

Classification report:
              precision    recall  f1-score   support

           0       0.85      0.92      0.88       450
           1       0.93      0.88      0.91       630
           2       0.94      0.80      0.87       150
           3       0.95      0.91      0.93       420
           4       0.88      0.93      0.91       690
           5       0.94      0.98      0.96       720
           6       0.99      0.91      0.95       270
           7       0.75      0.50      0.60        60
           8       0.93      0.95      0.94       690
           9       0.91      0.87      0.89        90

    accuracy                           0.92      4170
   macro avg       0.91      0.86      0.88      4170
weighted avg       0.92      0.92      0.92      4170


--------------------------------------------------------

nn3 = MLPClassifier(hidden_layer_sizes=20, activation='relu',
                    momentum =0.9, learning_rate_init=0.001, max_iter=200)

Results using train set
0.9718226833294035


Confusion matrix from ten cross validation:
[[360  76   0   0   2   4   0   0   5   0]
 [ 41 539   0   1   7   9   0   0   7   0]
 [  1   2 129   0   3   0   0   5   0   0]
 [  0  10   0 428  13   0   0   0   3   0]
 [  3  19   0  10 648   5   0   0   4   0]
 [  3   1   0   2  16 711   1   0   5   2]
 [  0   1   0   0   2   0 234   0   2   0]
 [ 11   0  13   0   7   0   0  52   1   0]
 [  5   5   0   0  10   5   0   0 679   0]
 [  0   1   0   0   4   1   0   0   0  70]]


Classification report
              precision    recall  f1-score   support

           0       0.85      0.81      0.83       447
           1       0.82      0.89      0.86       604
           2       0.91      0.92      0.91       140
           3       0.97      0.94      0.96       454
           4       0.91      0.94      0.93       689
           5       0.97      0.96      0.96       741
           6       1.00      0.98      0.99       239
           7       0.91      0.62      0.74        84
           8       0.96      0.96      0.96       704
           9       0.97      0.92      0.95        76

    accuracy                           0.92      4178
   macro avg       0.93      0.89      0.91      4178
weighted avg       0.92      0.92      0.92      4178

Using test set ------------------------------------------------------------
Results using test set:
0.919664268585132

Confusion matrix using test set:
[[382  57   6   1   2   2   0   0   0   0]
 [ 32 582   0   0  11   3   0   0   2   0]
 [ 11  12 106   0   4   0   0  11   6   0]
 [  0   3   0 398  15   2   0   0   1   1]
 [  0   9   1   8 654  11   0   3   4   0]
 [  1   0   0   2   3 707   0   0   4   3]
 [  8   1   0   0   1   0 250   0  10   0]
 [  0   0   0   0  27   0   0  33   0   0]
 [ 10   4   0   0  14   3  21   0 638   0]
 [  0   1   0   1   1   1   1   0   0  85]]

Classification report:
              precision    recall  f1-score   support

           0       0.86      0.85      0.85       450
           1       0.87      0.92      0.90       630
           2       0.94      0.71      0.81       150
           3       0.97      0.95      0.96       420
           4       0.89      0.95      0.92       690
           5       0.97      0.98      0.98       720
           6       0.92      0.93      0.92       270
           7       0.70      0.55      0.62        60
           8       0.96      0.92      0.94       690
           9       0.96      0.94      0.95        90

    accuracy                           0.92      4170
   macro avg       0.90      0.87      0.88      4170
weighted avg       0.92      0.92      0.92      4170


--------------------------------------------------------

nn4 = MLPClassifier(hidden_layer_sizes=30, activation='relu',
                    momentum =0.9, learning_rate_init=0.001, max_iter=200)

Results using train set
0.9775996227304881


Confusion matrix from ten cross validation:
[[374  60   1   0   4   6   0   0 2   0]
 [ 39 542   0   1   7   8   0   0   6   1]
 [  0   1 131   0   3   0   0   5   0   0]
 [  1   6   0 436   7   0   0   2   2   0]
 [  4  15   0   9 649   4   0   3   5   0]
 [  0   2   1   1  14 715   0   0   7   1]
 [  0   0   0   0   1   0 236   0   2   0]
 [ 10   1   5   0   2   0   0  65   1   0]
 [  5   3   0   0   8   3   0   0 685   0]
 [  0   0   0   0   2   2   0   0   0  72]]


Classification report
              precision    recall  f1-score   support

           0       0.86      0.84      0.85       447
           1       0.86      0.90      0.88       604
           2       0.95      0.94      0.94       140
           3       0.98      0.96      0.97       454
           4       0.93      0.94      0.94       689
           5       0.97      0.96      0.97       741
           6       1.00      0.99      0.99       239
           7       0.87      0.77      0.82        84
           8       0.96      0.97      0.97       704
           9       0.97      0.95      0.96        76

    accuracy                           0.93      4178
   macro avg       0.94      0.92      0.93      4178
weighted avg       0.93      0.93      0.93      4178

Using test set ------------------------------------------------------------
Results using test set:
0.9167865707434053

Confusion matrix using test set:
[[357  78   7   0   3   3   0   0   2   0]
 [ 10 601   0   0  14   1   0   0   4   0]
 [  1  21 112   0   3   0   0   8   5   0]
 [  0   1   0 395  20   1   0   0   1   2]
 [  0  11   0   4 658  11   0   1   5   0]
 [  1   0   0   1   2 710   0   0   4   2]
 [ 10   1   0   0   0   0 251   0   8   0]
 [  0   0   0   0  26   0   0  34   0   0]
 [  7   3   0   7  37   6   3   7 620   0]
 [  0   0   1   0   4   0   0   0   0  85]]

Classification report:
              precision    recall  f1-score   support

           0       0.92      0.79      0.85       450
           1       0.84      0.95      0.89       630
           2       0.93      0.75      0.83       150
           3       0.97      0.94      0.96       420
           4       0.86      0.95      0.90       690
           5       0.97      0.99      0.98       720
           6       0.99      0.93      0.96       270
           7       0.68      0.57      0.62        60
           8       0.96      0.90      0.93       690
           9       0.96      0.94      0.95        90

    accuracy                           0.92      4170
   macro avg       0.91      0.87      0.89      4170
weighted avg       0.92      0.92      0.92      4170


--------------------------------------------------------

nn5 = MLPClassifier(hidden_layer_sizes=50, activation='relu',
                   momentum =0.9, learning_rate_init=0.001, max_iter=200)

Results using train set
0.9854987031360528


Confusion matrix from ten cross validation:
[[382  54   1   0   2   6   0   0   2   0]
 [ 29 554   0   1   7   7   0   0   5   1]
 [  1   0 131   0   3   0   0   5   0   0]
 [  0   6   0 435   9   0   0   2   2   0]
 [  2  11   0   5 659   4   0   1   7   0]
 [  1   2   1   1  14 715   1   0   6   0]
 [  0   0   0   0   1   1 234   0   3   0]
 [  9   2   5   0   5   1   0  61   1   0]
 [  3   4   0   0   6   3   0   0 688   0]
 [  0   1   0   0   1   1   0   0   0  73]]


Classification report
              precision    recall  f1-score   support

           0       0.89      0.85      0.87       447
           1       0.87      0.92      0.89       604
           2       0.95      0.94      0.94       140
           3       0.98      0.96      0.97       454
           4       0.93      0.96      0.94       689
           5       0.97      0.96      0.97       741
           6       1.00      0.98      0.99       239
           7       0.88      0.73      0.80        84
           8       0.96      0.98      0.97       704
           9       0.99      0.96      0.97        76

    accuracy                           0.94      4178
   macro avg       0.94      0.92      0.93      4178
weighted avg       0.94      0.94      0.94      4178

Using test set ------------------------------------------------------------
Results using test set:
0.9211031175059952

Confusion matrix using test set:
[[382  56   4   0   4   3   0   0   1   0]
 [ 25 594   0   1   7   1   0   0   2   0]
 [  6  10 110   0   2   0   0  19   3   0]
 [  0   1   0 396  18   3   0   0   0   2]
 [  1   1   0  11 664  11   0   0   2   0]
 [  0   0   0   1   3 711   0   0   4   1]
 [ 10   4   0   0   0   0 252   0   4   0]
 [  0   0   0   0  19   0   0  41   0   0]
 [  8   2   0   3  34   3  16  19 605   0]
 [  0   1   0   0   3   0   0   0   0  86]]

Classification report:
              precision    recall  f1-score   support

           0       0.88      0.85      0.87       450
           1       0.89      0.94      0.91       630
           2       0.96      0.73      0.83       150
           3       0.96      0.94      0.95       420
           4       0.88      0.96      0.92       690
           5       0.97      0.99      0.98       720
           6       0.94      0.93      0.94       270
           7       0.52      0.68      0.59        60
           8       0.97      0.88      0.92       690
           9       0.97      0.96      0.96        90

    accuracy                           0.92      4170
   macro avg       0.89      0.89      0.89      4170
weighted avg       0.92      0.92      0.92      4170


--------------------------------------------------------
--------------------------------------------------------
-------------------CHANGE MAX ITERATION-----------------
--------------------------------------------------------
--------------------------------------------------------

nn6 = MLPClassifier(hidden_layer_sizes=20, activation='relu',
                    momentum =0.9, learning_rate_init=0.001, max_iter=50)

Results using train set
0.9157038434331526


Confusion matrix from ten cross validation:
[[165 225   0   0   4  22   7   0  24   0]
 [ 82 469   0   4  18  10   1   0  20   0]
 [  3   7  77   0  52   0   0   0   1   0]
 [  0   5   0 415  30   0   0   0   4   0]
 [  4  40   0   7 613   3   1   0  21   0]
 [  0   5   0   2  23 694   0   0  17   0]
 [  8   2   0   0   2   2 199   0  26   0]
 [  3   5  30   0  38   1   1   3   3   0]
 [  7   5   0   0  10   8   1   0 673   0]
 [  1  20   0   0  24  15   0   0   5  11]]


Classification report
              precision    recall  f1-score   support

           0       0.60      0.37      0.46       447
           1       0.60      0.78      0.68       604
           2       0.72      0.55      0.62       140
           3       0.97      0.91      0.94       454
           4       0.75      0.89      0.82       689
           5       0.92      0.94      0.93       741
           6       0.95      0.83      0.89       239
           7       1.00      0.04      0.07        84
           8       0.85      0.96      0.90       704
           9       1.00      0.14      0.25        76

    accuracy                           0.79      4178
   macro avg       0.84      0.64      0.65      4178
weighted avg       0.80      0.79      0.78      4178

Using test set ------------------------------------------------------------
Results using test set:
0.8719424460431655

Confusion matrix using test set:
[[293 128   5   3   4   3   1   0  13   0]
 [ 60 526   0   2  16   5   0   1  20   0]
 [ 31   1 101   0   4   0   0  12   1   0]
 [  0   2   0 381  35   1   0   0   1   0]
 [  1  19   0  16 634  12   0   0   8   0]
 [  0   1   0   2   2 703   0   0  10   2]
 [ 10   2   0   0   2   0 248   0   8   0]
 [  0   0  19   0  30   0   0  11   0   0]
 [  1   1   0   1  11   5   2  13 656   0]
 [  0   0   0   3   3   1   0   0   0  83]]

Classification report:
              precision    recall  f1-score   support

           0       0.74      0.65      0.69       450
           1       0.77      0.83      0.80       630
           2       0.81      0.67      0.73       150
           3       0.93      0.91      0.92       420
           4       0.86      0.92      0.89       690
           5       0.96      0.98      0.97       720
           6       0.99      0.92      0.95       270
           7       0.30      0.18      0.23        60
           8       0.91      0.95      0.93       690
           9       0.98      0.92      0.95        90

    accuracy                           0.87      4170
   macro avg       0.83      0.79      0.81      4170
weighted avg       0.87      0.87      0.87      4170


--------------------------------------------------------

nn7 = MLPClassifier(hidden_layer_sizes=(20,), activation='relu',
                    momentum=0.9, learning_rate_init=0.001, max_iter=100)

Results using train set
0.9490686158924782


Confusion matrix from ten cross validation:
[[247 165   0   1   3  14   1   0  16   0]
 [ 83 487   0   4   9   8   1   0  11   1]
 [  0   6 112   0  21   0   0   1   0   0]
 [  1   6   0 423  21   1   0   0   2   0]
 [ 10  21   0   5 636   7   0   0  10   0]
 [  1   4   0   3  19 702   0   0  12   0]
 [  1   0   0   0   1   1 222   0  14   0]
 [  7   3  37   0  21   1   0  11   4   0]
 [  5   9   0   0   7   5   3   0 675   0]
 [  2   4   0   2   8   5   6   0   5  44]]


Classification report
              precision    recall  f1-score   support

           0       0.69      0.55      0.61       447
           1       0.69      0.81      0.74       604
           2       0.75      0.80      0.78       140
           3       0.97      0.93      0.95       454
           4       0.85      0.92      0.89       689
           5       0.94      0.95      0.95       741
           6       0.95      0.93      0.94       239
           7       0.92      0.13      0.23        84
           8       0.90      0.96      0.93       704
           9       0.98      0.58      0.73        76

    accuracy                           0.85      4178
   macro avg       0.86      0.76      0.77      4178
weighted avg       0.85      0.85      0.84      4178

Using test set ------------------------------------------------------------
Results using test set:
0.9016786570743405

Confusion matrix using test set:
[[328 109   4   3   2   2   1   0   1   0]
 [ 35 574   0   1   9   7   0   0   4   0]
 [ 14  11 105   0   1   0   0  17   2   0]
 [  1   1   0 387  27   1   0   0   1   2]
 [  0  12   0   9 650  14   0   1   4   0]
 [  0   0   0   1   2 710   0   0   5   2]
 [ 10   2   0   0   1   0 252   0   5   0]
 [  0   0   6   0  30   0   0  24   0   0]
 [  6   5   0   0  15   8   9   0 647   0]
 [  0   1   0   2   3   1   0   0   0  83]]

Classification report:
              precision    recall  f1-score   support

           0       0.83      0.73      0.78       450
           1       0.80      0.91      0.85       630
           2       0.91      0.70      0.79       150
           3       0.96      0.92      0.94       420
           4       0.88      0.94      0.91       690
           5       0.96      0.99      0.97       720
           6       0.96      0.93      0.95       270
           7       0.57      0.40      0.47        60
           8       0.97      0.94      0.95       690
           9       0.95      0.92      0.94        90

    accuracy                           0.90      4170
   macro avg       0.88      0.84      0.86      4170
weighted avg       0.90      0.90      0.90      4170


--------------------------------------------------------

nn8 = MLPClassifier(hidden_layer_sizes=(20,), activation='relu',
                    momentum=0.9, learning_rate_init=0.01, max_iter=200)

Results using train set
0.9939872671539731


Confusion matrix from ten cross validation:
[[378  54   0   0   1   6   2   2   4   0]
 [ 10 575   0   4   9   4   0   0   2   0]
 [  0   1 130   0   3   1   0   5   0   0]
 [  3   7   1 434   6   0   0   2   1   0]
 [  0  12   1  12 652   5   0   2   4   1]
 [  4   2   2   5  10 709   2   1   6   0]
 [  1   0   0   0   0   1 234   0   3   0]
 [  2   1   2   1   3   0   0  74   1   0]
 [  6   0   0   1   4   1   3   1 688   0]
 [  0   0   0   0   0   0   2   0   0  74]]


Classification report
              precision    recall  f1-score   support

           0       0.94      0.85      0.89       447
           1       0.88      0.95      0.92       604
           2       0.96      0.93      0.94       140
           3       0.95      0.96      0.95       454
           4       0.95      0.95      0.95       689
           5       0.98      0.96      0.97       741
           6       0.96      0.98      0.97       239
           7       0.85      0.88      0.87        84
           8       0.97      0.98      0.97       704
           9       0.99      0.97      0.98        76

    accuracy                           0.94      4178
   macro avg       0.94      0.94      0.94      4178
weighted avg       0.95      0.94      0.94      4178

Using test set ------------------------------------------------------------
Results using test set:
0.9225419664268585

Confusion matrix using test set:
[[424  16   4   0   1   2   0   1   2   0]
 [ 31 585   1   1   2   1   1   2   2   4]
 [  0   2 115   2   0   0   0  22   9   0]
 [  1   0   0 399  13   2   0   2   1   2]
 [  5  10   1   5 642  21   0   3   3   0]
 [ 13   0   0   1   1 701   0   0   3   1]
 [  6   1   0   0   0   0 237   0  26   0]
 [  0   0   0   0  25   0   0  34   1   0]
 [ 12   5   0   1  11   6  18   1 636   0]
 [  0   2   0   2   2  10   0   0   0  74]]

Classification report:
              precision    recall  f1-score   support

           0       0.86      0.94      0.90       450
           1       0.94      0.93      0.94       630
           2       0.95      0.77      0.85       150
           3       0.97      0.95      0.96       420
           4       0.92      0.93      0.93       690
           5       0.94      0.97      0.96       720
           6       0.93      0.88      0.90       270
           7       0.52      0.57      0.54        60
           8       0.93      0.92      0.93       690
           9       0.91      0.82      0.87        90

    accuracy                           0.92      4170
   macro avg       0.89      0.87      0.88      4170
weighted avg       0.92      0.92      0.92      4170


--------------------------------------------------------

nn9 = MLPClassifier(hidden_layer_sizes=(20,), activation='relu',
                    momentum=0.9, learning_rate_init=0.1, max_iter=200)

Results using train set
0.9277293091252063


Confusion matrix from ten cross validation:
[[203  60   1  13  67  51   3   3  46   0]
 [ 42 300   2  38  81  76   2   1  62   0]
 [  6   1  57   1  26  14   0   7  28   0]
 [  8   8   1 257  64  48   0   1  67   0]
 [  4  12   0  14 488  91   1   3  76   0]
 [  7   5   0   1  89 548   5   0  86   0]
 [  3   1   0   3  43  29 114   0  46   0]
 [  2   2   1   0  19  11   0  32  17   0]
 [  3   0   0   8  85  90   2   0 516   0]
 [ 10   1   0   4  11  21   3   0   8  18]]


Classification report
              precision    recall  f1-score   support

           0       0.70      0.45      0.55       447
           1       0.77      0.50      0.60       604
           2       0.92      0.41      0.56       140
           3       0.76      0.57      0.65       454
           4       0.50      0.71      0.59       689
           5       0.56      0.74      0.64       741
           6       0.88      0.48      0.62       239
           7       0.68      0.38      0.49        84
           8       0.54      0.73      0.62       704
           9       1.00      0.24      0.38        76

    accuracy                           0.61      4178
   macro avg       0.73      0.52      0.57      4178
weighted avg       0.66      0.61      0.60      4178

Using test set ------------------------------------------------------------
Results using test set:
0.8762589928057554

Confusion matrix using test set:
[[376  58   2   3   3   5   0   1   2   0]
 [ 61 530   3   0  16   7   1   0  12   0]
 [ 12   4 116  10   4   0   1   2   1   0]
 [  1   0   0 386  13   1  11   2   5   1]
 [  4   0   5   3 647   4   6   1  20   0]
 [  0   1   0   1   1 660   1   0  56   0]
 [  0   0   0   1   2   0 217   0  50   0]
 [  0   0  14   3  17   0  13  13   0   0]
 [  0   0   0   2  12   0  26   0 650   0]
 [  0   2   1   0  17   2   0   1   8  59]]

Classification report:
              precision    recall  f1-score   support

           0       0.83      0.84      0.83       450
           1       0.89      0.84      0.87       630
           2       0.82      0.77      0.80       150
           3       0.94      0.92      0.93       420
           4       0.88      0.94      0.91       690
           5       0.97      0.92      0.94       720
           6       0.79      0.80      0.79       270
           7       0.65      0.22      0.33        60
           8       0.81      0.94      0.87       690
           9       0.98      0.66      0.79        90

    accuracy                           0.88      4170
   macro avg       0.86      0.78      0.81      4170
weighted avg       0.88      0.88      0.87      4170


--------------------------------------------------------
--------------------------------------------------------
--------------------------------------------------------
---------------------CHANGE MOMENTUM--------------------
--------------------------------------------------------
--------------------------------------------------------

nn10 = MLPClassifier(hidden_layer_sizes=(20,), activation='relu',
                    momentum=0.7, learning_rate_init=0.001,max_iter=200)

Results using train set
0.9678141947653855


Confusion matrix from ten cross validation:
[[355  74   0   1   2   7   0   0   8   0]
 [ 41 538   0   1  10   8   0   0   5   1]
 [  2   0 126   0   6   0   0   6   0   0]
 [  0   5   0 432  14   0   0   0   3   0]
 [  8  15   0   8 645   4   0   1   8   0]
 [  3   1   1   1  14 712   0   0   7   2]
 [  0   0   0   1   1   0 233   0   4   0]
 [ 10   0  13   0   7   0   0  53   1   0]
 [  8   3   0   1   5   3   0   0 684   0]
 [  0   4   0   0   2   1   0   0   0  69]]


Classification report
              precision    recall  f1-score   support

           0       0.83      0.79      0.81       447
           1       0.84      0.89      0.86       604
           2       0.90      0.90      0.90       140
           3       0.97      0.95      0.96       454
           4       0.91      0.94      0.92       689
           5       0.97      0.96      0.96       741
           6       1.00      0.97      0.99       239
           7       0.88      0.63      0.74        84
           8       0.95      0.97      0.96       704
           9       0.96      0.91      0.93        76

    accuracy                           0.92      4178
   macro avg       0.92      0.89      0.90      4178
weighted avg       0.92      0.92      0.92      4178

Using test set ------------------------------------------------------------
Results using test set:
0.9225419664268585

Confusion matrix using test set:
[[381  56   5   1   2   3   0   1   1   0]
 [ 27 585   0   2   8   5   0   0   2   1]
 [ 13   5 109   0   4   0   0  13   6   0]
 [  0   0   0 396  20   1   0   0   1   2]
 [  0   9   0   1 661  15   0   1   3   0]
 [  1   0   0   1   3 708   0   0   5   2]
 [  6   2   0   0   1   0 257   0   4   0]
 [  0   0   0   0  30   0   0  30   0   0]
 [  9   2   0   0  24   2  16   0 637   0]
 [  0   1   0   1   4   1   0   0   0  83]]

Classification report:
              precision    recall  f1-score   support

           0       0.87      0.85      0.86       450
           1       0.89      0.93      0.91       630
           2       0.96      0.73      0.83       150
           3       0.99      0.94      0.96       420
           4       0.87      0.96      0.91       690
           5       0.96      0.98      0.97       720
           6       0.94      0.95      0.95       270
           7       0.67      0.50      0.57        60
           8       0.97      0.92      0.94       690
           9       0.94      0.92      0.93        90

    accuracy                           0.92      4170
   macro avg       0.91      0.87      0.88      4170
weighted avg       0.92      0.92      0.92      4170


--------------------------------------------------------

nn11 = MLPClassifier(hidden_layer_sizes=(20,), activation='relu',
                    momentum=0.5,learning_rate_init=0.001,max_iter=200)

Results using train set
0.9676962980429145


Confusion matrix from ten cross validation:
[[347  84   1   0   3   9   0   0   3   0]
 [ 41 540   0   0   9   8   1   0   5   0]
 [  2   0 128   0   3   0   0   7   0   0]
 [  0   8   0 428  16   0   0   0   2   0]
 [  5  20   0   6 648   5   0   0   5   0]
 [  1   1   0   3  17 712   1   0   6   0]
 [  0   0   0   0   2   1 233   0   3   0]
 [ 10   1  13   0   6   1   0  52   1   0]
 [  8   3   0   0  10   5   0   0 678   0]
 [  1   0   0   0   2   1   0   0   0  72]]


Classification report
              precision    recall  f1-score   support

           0       0.84      0.78      0.81       447
           1       0.82      0.89      0.86       604
           2       0.90      0.91      0.91       140
           3       0.98      0.94      0.96       454
           4       0.91      0.94      0.92       689
           5       0.96      0.96      0.96       741
           6       0.99      0.97      0.98       239
           7       0.88      0.62      0.73        84
           8       0.96      0.96      0.96       704
           9       1.00      0.95      0.97        76

    accuracy                           0.92      4178
   macro avg       0.92      0.89      0.91      4178
weighted avg       0.92      0.92      0.92      4178

Using test set ------------------------------------------------------------
Results using test set:
0.919664268585132

Confusion matrix using test set:
[[376  64   4   0   3   2   1   0   0   0]
 [ 29 582   0   0  10   5   0   0   2   2]
 [ 14  10 110   0   2   0   0  11   3   0]
 [  0   2   0 391  24   0   0   0   1   2]
 [  1  10   0   1 660  16   0   0   2   0]
 [  0   0   0   1   3 711   0   0   4   1]
 [  7   3   0   0   0   0 254   0   6   0]
 [  0   0   0   0  28   0   0  32   0   0]
 [ 10   4   0   0  24   5  11   0 636   0]
 [  0   1   0   0   5   1   0   0   0  83]]

Classification report:
              precision    recall  f1-score   support

           0       0.86      0.84      0.85       450
           1       0.86      0.92      0.89       630
           2       0.96      0.73      0.83       150
           3       0.99      0.93      0.96       420
           4       0.87      0.96      0.91       690
           5       0.96      0.99      0.97       720
           6       0.95      0.94      0.95       270
           7       0.74      0.53      0.62        60
           8       0.97      0.92      0.95       690
           9       0.94      0.92      0.93        90

    accuracy                           0.92      4170
   macro avg       0.91      0.87      0.89      4170
weighted avg       0.92      0.92      0.92      4170


--------------------------------------------------------

nn12 = MLPClassifier(hidden_layer_sizes=(20,),momentum=0.5,learning_rate_init=0.001,
                      max_iter=200, early_stopping=True,validation_fraction=0.7)

Results using train set
0.9122848384814902


Confusion matrix from ten cross validation:
[[204 198   0   0   5  16   4   0  20   0]
 [ 95 464   1   2  10  16   0   0  16   0]
 [  2  13 101   0  22   0   0   0   2   0]
 [  0   9   0 410  31   1   0   0   3   0]
 [ 19  34   0   4 611   2   1   0  18   0]
 [  0   7   0   2  17 700   1   0  14   0]
 [  9   3   0   1   6   1 203   0  16   0]
 [  6   5  39   0  21   1   1   5   6   0]
 [ 10   5   0   0  10   6   2   0 671   0]
 [  3   8   0   5  22  17   1   0   1  19]]


Classification report
              precision    recall  f1-score   support

           0       0.59      0.46      0.51       447
           1       0.62      0.77      0.69       604
           2       0.72      0.72      0.72       140
           3       0.97      0.90      0.93       454
           4       0.81      0.89      0.85       689
           5       0.92      0.94      0.93       741
           6       0.95      0.85      0.90       239
           7       1.00      0.06      0.11        84
           8       0.87      0.95      0.91       704
           9       1.00      0.25      0.40        76

    accuracy                           0.81      4178
   macro avg       0.84      0.68      0.70      4178
weighted avg       0.82      0.81      0.80      4178

Using test set ------------------------------------------------------------
Results using test set:
0.8709832134292566

Confusion matrix using test set:
[[292 132   5   1   4   4   1   0  11   0]
 [ 43 550   0   2  11   5   0   0  19   0]
 [  5  27 112   0   3   0   0   0   3   0]
 [  1   0   0 375  41   1   2   0   0   0]
 [  2  18   0  15 635  15   0   0   5   0]
 [  0   0   0   2   4 704   0   0   8   2]
 [ 11   1   0   0   0   1 246   0  11   0]
 [  0   0  29   0  30   0   0   1   0   0]
 [  1   1   0   4  26  12   7   0 639   0]
 [  1   1   0   2   6   2   0   0   0  78]]

Classification report:
              precision    recall  f1-score   support

           0       0.82      0.65      0.72       450
           1       0.75      0.87      0.81       630
           2       0.77      0.75      0.76       150
           3       0.94      0.89      0.91       420
           4       0.84      0.92      0.88       690
           5       0.95      0.98      0.96       720
           6       0.96      0.91      0.94       270
           7       1.00      0.02      0.03        60
           8       0.92      0.93      0.92       690
           9       0.97      0.87      0.92        90

    accuracy                           0.87      4170
   macro avg       0.89      0.78      0.78      4170
weighted avg       0.88      0.87      0.86      4170


--------------------------------------------------------

nn13 = MLPClassifier(hidden_layer_sizes=(20,),momentum=0.5,learning_rate_init=0.001,
                      max_iter=200, early_stopping=True,validation_fraction=0.5)

Results using train set
0.9455317142183447


Confusion matrix from ten cross validation:
[[284 128   1   0   7  12   1   0  14   0]
 [ 87 484   1   6   7   7   1   0  10   1]
 [  1   6 124   0   7   0   0   0   2   0]
 [  1   7   0 423  21   0   0   0   2   0]
 [  7  22   0  10 639   5   0   0   6   0]
 [  2   4   0   4  15 706   1   0   8   1]
 [  0   0   0   0   2   3 227   0   7   0]
 [  8   1  32   0  16   1   0  22   4   0]
 [ 11   4   0   0   7   3   1   0 678   0]
 [  0   4   0   0   4   8   1   0   0  59]]


Classification report
              precision    recall  f1-score   support

           0       0.71      0.64      0.67       447
           1       0.73      0.80      0.77       604
           2       0.78      0.89      0.83       140
           3       0.95      0.93      0.94       454
           4       0.88      0.93      0.90       689
           5       0.95      0.95      0.95       741
           6       0.98      0.95      0.96       239
           7       1.00      0.26      0.42        84
           8       0.93      0.96      0.94       704
           9       0.97      0.78      0.86        76

    accuracy                           0.87      4178
   macro avg       0.89      0.81      0.83      4178
weighted avg       0.88      0.87      0.87      4178

Using test set ------------------------------------------------------------
Results using test set:
0.8971223021582734

Confusion matrix using test set:
[[317 114   5   2   3   2   0   0   7   0]
 [ 29 575   0   1  13   4   0   0   8   0]
 [ 14  10 108   0   8   0   0   4   6   0]
 [  0   5   0 379  33   1   0   0   1   1]
 [  1   8   1  17 650  10   0   1   2   0]
 [  0   0   0   1   6 707   0   0   4   2]
 [  2   4   0   0   1   0 251   0  12   0]
 [  0   0   2   0  30   0   0  28   0   0]
 [  3   2   0   0  22   6  14   0 643   0]
 [  0   1   0   2   2   1   1   0   0  83]]

Classification report:
              precision    recall  f1-score   support

           0       0.87      0.70      0.78       450
           1       0.80      0.91      0.85       630
           2       0.93      0.72      0.81       150
           3       0.94      0.90      0.92       420
           4       0.85      0.94      0.89       690
           5       0.97      0.98      0.97       720
           6       0.94      0.93      0.94       270
           7       0.85      0.47      0.60        60
           8       0.94      0.93      0.94       690
           9       0.97      0.92      0.94        90

    accuracy                           0.90      4170
   macro avg       0.91      0.84      0.86      4170
weighted avg       0.90      0.90      0.90      4170


--------------------------------------------------------


Process finished with exit code 0

